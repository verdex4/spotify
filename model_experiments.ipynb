{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a480538-d1e1-4a6b-a0fe-fba60298171d",
   "metadata": {},
   "source": [
    "### Вспомогательные конструкции для добавления признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc059a63-067a-44b5-bec6-db1f50962e3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "genre_groups = {\n",
    "    'mainstream': [\n",
    "        'pop', 'k-pop', 'dance', 'hip-hop', 'r-n-b',\n",
    "        'edm', 'pop-film', 'indie-pop'\n",
    "    ],\n",
    "    'rock_metal': [\n",
    "        'rock', 'metal', 'hard-rock', 'punk',\n",
    "        'alternative', 'alt-rock', 'grunge',\n",
    "        'heavy-metal', 'psych-rock', 'emo'\n",
    "    ],\n",
    "    'electronic': [\n",
    "        'electronic', 'techno', 'house', 'trance',\n",
    "        'dubstep', 'drum-and-bass', 'deep-house',\n",
    "        'techno', 'electro', 'hardstyle'\n",
    "    ],\n",
    "    'chill': [\n",
    "        'chill', 'ambient', 'acoustic', 'jazz',\n",
    "        'blues', 'folk', 'singer-songwriter',\n",
    "        'classical', 'piano', 'study', 'sleep'\n",
    "    ],\n",
    "    'world': [\n",
    "        'latin', 'reggae', 'salsa', 'samba',\n",
    "        'world-music', 'afrobeat', 'funk', 'disco',\n",
    "        'country', 'bluegrass', 'tango'\n",
    "    ],\n",
    "    'extreme': [\n",
    "        'metalcore', 'death-metal', 'black-metal',\n",
    "        'hardcore', 'grindcore', 'industrial'\n",
    "    ],\n",
    "    'soundtrack': [\n",
    "        'anime', 'disney', 'soundtrack', 'game',\n",
    "        'comedy', 'children', 'kids', 'show-tunes',\n",
    "        'j-pop', 'j-rock', 'k-pop', 'cantopop'\n",
    "    ]\n",
    "}\n",
    "\n",
    "def map_genre_group(genre):\n",
    "    for group, genres in genre_groups.items():\n",
    "        if genre in genres:\n",
    "            return group\n",
    "    return 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d720b617-9bc8-4504-aeb2-3e69cec23a79",
   "metadata": {},
   "source": [
    "### Загрузка датасета, добавление признаков из feature engineering, разбиение на train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca8352b-d92b-4a38-94ce-a2c69701cf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность: (113999, 19)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "df = pd.read_csv('dataset.csv')\n",
    "df.dropna(inplace=True)\n",
    "df.rename(columns={df.columns[0]: 'id'}, inplace=True) # первый столбец - id\n",
    "pd.set_option('display.max_columns', None) # отображение всех колонок\n",
    "target = 'popularity'\n",
    "\n",
    "df['music_type'] = df['track_genre'].apply(map_genre_group)\n",
    "df['duration_min'] = df['duration_ms'] / 1000 / 60\n",
    "df['artist_count'] = df['artists'].str.split(';').str.len()\n",
    "df['acousticness_pow_2.5'] = df['acousticness'] ** 2.5\n",
    "df['chill_quiet'] = df['acousticness'] ** 2 * (1 - df['energy']) * (1 - df['speechiness'])\n",
    "df['energy_pow_3.5'] = df['energy'] ** 3.5\n",
    "\n",
    "num = ['danceability', 'energy', 'loudness', 'speechiness',\n",
    "       'acousticness', 'instrumentalness', 'liveness',\n",
    "       'valence', 'tempo', 'duration_min', 'artist_count',\n",
    "       'acousticness_pow_2.5', 'chill_quiet', 'energy_pow_3.5'\n",
    "]\n",
    "cat = ['explicit', 'key', 'mode', 'time_signature', 'music_type']\n",
    "\n",
    "X = df[num + cat]\n",
    "y = df['popularity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Размерность: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd255b1c-e872-4208-89e3-62bfc4d965f2",
   "metadata": {},
   "source": [
    "### Функция для перебора параметров модели (валидация + тест)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37991427-15c4-4a6e-8d9a-97f12b02923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def find_best_model(model, params, n_iter=25):\n",
    "    num_indices = [X_train.columns.get_loc(col) for col in num]\n",
    "    cat_indices = [X_train.columns.get_loc(col) for col in cat]\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), num_indices),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_indices)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    params_with_prefix = {f'model__{key}': value for key, value in params.items()}\n",
    "    \n",
    "    search = RandomizedSearchCV(pipeline, params_with_prefix, cv=kfold, scoring='r2', n_jobs=-1, refit=True, random_state=42)\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    base_score = 0.0560 # из feature engineering, после добавления признаков\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "    \n",
    "    print(f\"Лучшие параметры: {search.best_params_}\")\n",
    "    print(f\"CV R^2 (средний): {search.best_score_:.4f}\")\n",
    "    print(f\"Test R^2: {test_score:.4f}\")\n",
    "    print(f\"Улучшение test R^2 на {(test_score - base_score):.4f}\")\n",
    "    \n",
    "    return best_model, search.best_score_, test_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537153b6-413d-4a77-9916-ff597d43870c",
   "metadata": {},
   "source": [
    "### Вспомогательная конструкция для перебора моделей и параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b272ba30-590a-4877-a46b-36211a22d0ec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "models = {\n",
    "    # линейные\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    \n",
    "    # деревья\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest Regressor': RandomForestRegressor(random_state=42),\n",
    "    'Extra Trees Regressor': ExtraTreesRegressor(random_state=42),\n",
    "    \n",
    "    # градиентный бустинг\n",
    "    'HistGradientBoosting Regressor': HistGradientBoostingRegressor(random_state=42),\n",
    "    'XG Boost Regressor': XGBRegressor(random_state=42),\n",
    "    'Light GBM Regressor': LGBMRegressor(random_state=42),\n",
    "    'CatBoost Regressor': CatBoostRegressor(random_state=42, verbose=0),\n",
    "\n",
    "    # нейросети\n",
    "    'MLP Regressor': MLPRegressor(random_state=42, max_iter=500)\n",
    "}\n",
    "\n",
    "all_params = [\n",
    "    # Linear Regression\n",
    "    {},\n",
    "    \n",
    "    # Ridge\n",
    "    {'alpha': [0.001, 0.005, 0.01, 0.05] + list(np.arange(0.1, 2.1, 0.1))},\n",
    "    \n",
    "    # Lasso\n",
    "    {'alpha': [0.001, 0.005, 0.01, 0.05] + list(np.arange(0.1, 2.1, 0.1))},\n",
    "    \n",
    "    # ElasticNet\n",
    "    {\n",
    "        'alpha': [0.001, 0.005, 0.01, 0.05] + list(np.arange(0.1, 2.1, 0.1)),\n",
    "        'l1_ratio': np.arange(0.1, 1.0, 0.1).tolist()\n",
    "    },\n",
    "    \n",
    "    # Decision Tree\n",
    "    {\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 10, 20, 30, 50],\n",
    "        'min_samples_leaf': [1, 5, 20],\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    },\n",
    "    \n",
    "    # Random Forest Regressor\n",
    "    {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 15, 20],\n",
    "        'min_samples_split': [2, 10, 50],\n",
    "        'min_samples_leaf': [1, 5, 20],\n",
    "        'max_features': ['sqrt', 0.5, 0.7],\n",
    "        'bootstrap': [True],\n",
    "        'n_jobs': [-1]\n",
    "    },\n",
    "    \n",
    "    # Extra Trees Regressor\n",
    "    {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 15, 20],\n",
    "        'min_samples_split': [2, 10],\n",
    "        'min_samples_leaf': [1, 5],\n",
    "        'max_features': ['sqrt', 0.5],\n",
    "        'bootstrap': [True],\n",
    "        'n_jobs': [-1]\n",
    "    },\n",
    "    \n",
    "    # HistGradientBoosting Regressor\n",
    "    {\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'max_iter': [100, 200],\n",
    "        'max_depth': [None, 7, 9],\n",
    "        'min_samples_leaf': [20, 50, 100],\n",
    "        'max_leaf_nodes': [None, 63],\n",
    "        'l2_regularization': [0.0, 0.1, 1.0]\n",
    "    },\n",
    "    \n",
    "    # XG Boost Regressor\n",
    "    {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'max_depth': [5, 7, 9],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "        'gamma': [0, 0.5],\n",
    "        'reg_alpha': [0, 0.5],\n",
    "        'reg_lambda': [1, 2],\n",
    "        'n_jobs': [-1],\n",
    "        'tree_method': ['hist']\n",
    "    },\n",
    "    \n",
    "    # Light GBM Regressor\n",
    "    {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'num_leaves': [31, 63],\n",
    "        'max_depth': [None, 7],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "        'reg_alpha': [0, 0.5],\n",
    "        'reg_lambda': [0, 0.5],\n",
    "        'n_jobs': [-1]\n",
    "    },\n",
    "    \n",
    "    # CatBoost Regressor\n",
    "    {\n",
    "        'iterations': [200, 500],\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'depth': [6, 8],\n",
    "        'l2_leaf_reg': [3, 7],\n",
    "        'border_count': [128],\n",
    "        'verbose': [False],\n",
    "    },\n",
    "    \n",
    "    # MLP Regressor - КРАЙНЕ УПРОЩЕНО\n",
    "    {\n",
    "        'hidden_layer_sizes': [(50,), (100,)],\n",
    "        'activation': ['relu'],\n",
    "        'alpha': [0.001, 0.01],\n",
    "        'learning_rate_init': [0.001, 0.01],\n",
    "        'batch_size': [256, 512],\n",
    "        'solver': ['adam'],\n",
    "        'early_stopping': [True],\n",
    "        'max_iter': [200],\n",
    "        'n_iter_no_change': [10]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3bee78-0dbf-468c-8651-134d719516d3",
   "metadata": {},
   "source": [
    "### Перебор и поиск лучших моделей из разных категорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf86f72-3af2-4ed8-84c1-7c50ef8de619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Лучшие параметры: {}\n",
      "CV R^2 (средний): 0.0587\n",
      "Test R^2: 0.0560\n",
      "Улучшение test R^2 на 0.0000\n",
      "\n",
      "Ridge\n",
      "Лучшие параметры: {'model__alpha': np.float64(1.8000000000000003)}\n",
      "CV R^2 (средний): 0.0587\n",
      "Test R^2: 0.0560\n",
      "Улучшение test R^2 на 0.0000\n",
      "\n",
      "Lasso\n",
      "Лучшие параметры: {'model__alpha': 0.001}\n",
      "CV R^2 (средний): 0.0587\n",
      "Test R^2: 0.0560\n",
      "Улучшение test R^2 на 0.0000\n",
      "\n",
      "ElasticNet\n",
      "Лучшие параметры: {'model__l1_ratio': 0.7000000000000001, 'model__alpha': 0.005}\n",
      "CV R^2 (средний): 0.0586\n",
      "Test R^2: 0.0559\n",
      "Улучшение test R^2 на -0.0001\n",
      "\n",
      "Decision Tree\n",
      "Лучшие параметры: {'model__min_samples_split': 20, 'model__min_samples_leaf': 20, 'model__max_features': None, 'model__max_depth': None}\n",
      "CV R^2 (средний): 0.1477\n",
      "Test R^2: 0.1658\n",
      "Улучшение test R^2 на 0.1098\n",
      "\n",
      "Random Forest Regressor\n",
      "Лучшие параметры: {'model__n_jobs': -1, 'model__n_estimators': 100, 'model__min_samples_split': 2, 'model__min_samples_leaf': 1, 'model__max_features': 0.7, 'model__max_depth': 20, 'model__bootstrap': True}\n",
      "CV R^2 (средний): 0.3905\n",
      "Test R^2: 0.4137\n",
      "Улучшение test R^2 на 0.3577\n",
      "\n",
      "Extra Trees Regressor\n",
      "Лучшие параметры: {'model__n_jobs': -1, 'model__n_estimators': 100, 'model__min_samples_split': 2, 'model__min_samples_leaf': 1, 'model__max_features': 0.5, 'model__max_depth': 20, 'model__bootstrap': True}\n",
      "CV R^2 (средний): 0.3298\n",
      "Test R^2: 0.3479\n",
      "Улучшение test R^2 на 0.2919\n",
      "\n",
      "HistGradientBoosting Regressor\n",
      "Лучшие параметры: {'model__min_samples_leaf': 20, 'model__max_leaf_nodes': None, 'model__max_iter': 100, 'model__max_depth': None, 'model__learning_rate': 0.1, 'model__l2_regularization': 0.1}\n",
      "CV R^2 (средний): 0.4513\n",
      "Test R^2: 0.4842\n",
      "Улучшение test R^2 на 0.4282\n",
      "\n",
      "XG Boost Regressor\n",
      "Лучшие параметры: {'model__tree_method': 'hist', 'model__subsample': 0.8, 'model__reg_lambda': 1, 'model__reg_alpha': 0.5, 'model__n_jobs': -1, 'model__n_estimators': 200, 'model__max_depth': 9, 'model__learning_rate': 0.1, 'model__gamma': 0, 'model__colsample_bytree': 1.0}\n",
      "CV R^2 (средний): 0.4275\n",
      "Test R^2: 0.4462\n",
      "Улучшение test R^2 на 0.3902\n",
      "\n",
      "Light GBM Regressor\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3394\n",
      "[LightGBM] [Info] Number of data points in the train set: 91199, number of used features: 43\n",
      "[LightGBM] [Info] Start training from score 33.298644\n",
      "Лучшие параметры: {'model__subsample': 0.8, 'model__reg_lambda': 0, 'model__reg_alpha': 0.5, 'model__num_leaves': 63, 'model__n_jobs': -1, 'model__n_estimators': 100, 'model__max_depth': None, 'model__learning_rate': 0.2, 'model__colsample_bytree': 1.0}\n",
      "CV R^2 (средний): 0.3176\n",
      "Test R^2: 0.3233\n",
      "Улучшение test R^2 на 0.2673\n",
      "\n",
      "CatBoost Regressor\n",
      "Лучшие параметры: {'model__verbose': False, 'model__learning_rate': 0.2, 'model__l2_leaf_reg': 3, 'model__iterations': 500, 'model__depth': 6, 'model__border_count': 128}\n",
      "CV R^2 (средний): 0.2969\n",
      "Test R^2: 0.3035\n",
      "Улучшение test R^2 на 0.2475\n",
      "\n",
      "MLP Regressor\n",
      "Лучшие параметры: {'model__solver': 'adam', 'model__n_iter_no_change': 10, 'model__max_iter': 200, 'model__learning_rate_init': 0.01, 'model__hidden_layer_sizes': (100,), 'model__early_stopping': True, 'model__batch_size': 256, 'model__alpha': 0.01, 'model__activation': 'relu'}\n",
      "CV R^2 (средний): 0.1779\n",
      "Test R^2: 0.1874\n",
      "Улучшение test R^2 на 0.1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for (model_name, model), params in zip(models.items(), all_params):\n",
    "    print(model_name)\n",
    "    find_best_model(model, params)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443fa867-c07d-4cb0-b557-8575af051f83",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "**Лучшие модели**\n",
    "1. HistGradientBoostingRegressor: Test R^2 = 0.4842 (+0.4282 от базовой модели)\n",
    "2. XGBRegressor: Test R^2 = 0.4462 (+0.3902)\n",
    "3. RandomForestRegressor: Test R^2 = 0.4137 (+0.3577)\n",
    "\n",
    "Статистика по видам моделей:\n",
    "- Линейные модели не работают\n",
    "- Деревья и ансамбли работают хорошо\n",
    "- Модели градиентного бустинга - лучшие\n",
    "- Нейронные сети лучше линейных моделей, но хуже остальных\n",
    "\n",
    "Изменение метрики R^2 на тесте:\n",
    "- Feature engineering дал прирост с 0.0471 до 0.0560 (+0.0089)\n",
    "- Подбор модели дал улучшение с 0.0560 до 0.4842 (в 8.6 раз!)\n",
    "\n",
    "Таким образом, для предсказания популярности нужны сложные нелинейные модели. Градиентный бустинг и ансамбли деревьев дают наилучший результат."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
